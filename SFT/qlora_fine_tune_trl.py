# QLoRA Fine-tuning using TRL SFTTrainer
# 2025/7/30
# wenzhe

# è¿™æ˜¯ä¸€ä¸ªåŸºäºTRLåº“çš„SFTTrainerçš„QLoRAå¾®è°ƒè„šæœ¬
# SFTTrainer ä¸ä¼ ç»Ÿçš„Trainerç›¸æ¯”ï¼Œæœ‰ä»¥ä¸‹å‡ ç‚¹ä¼˜åŠ¿ï¼š
# 1. è‡ªåŠ¨å¤„ç†åˆ†è¯æ ¼å¼åŒ–ï¼ˆåªä¼ æ–‡æœ¬å°±å¯ä»¥äº†ï¼Œä¸éœ€è¦åŠ è¿›è¡Œé¢å¤–çš„å¤„ç†ï¼‰ä¸æ ‡ç­¾ç”Ÿæˆ
# 2. æ”¯æŒpackingä¼˜åŒ–ï¼šå¯ä»¥è‡ªåŠ¨æŒ‰é•¿åº¦åˆ†ç»„ï¼Œå‡å°‘å¡«å……ï¼Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚

import os
# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['HF_DATASETS_CACHE'] = '/data/wenzhe/huggingface/datasets'
os.environ['HF_HOME'] = '/data/wenzhe/huggingface'
os.environ['WANDB_PROJECT'] = 'qlora-chatbot-finetune-trl'
import random
from datetime import datetime
from typing import Dict, List, Optional
import torch
from datasets import Dataset, load_dataset
from transformers import (
    AutoModelForCausalLM,
    BitsAndBytesConfig,
    PreTrainedTokenizerFast,
)
from trl import SFTTrainer, SFTConfig
from peft import (
    LoraConfig,
    get_peft_model,
    TaskType,
    prepare_model_for_kbit_training,
)
import wandb
import multiprocessing

num_proc = max(1, multiprocessing.cpu_count() // 2)


def format_conversation(conversation: List[Dict]) -> str:
    """å°†å¯¹è¯æ ¼å¼åŒ–ä¸ºè®­ç»ƒæ–‡æœ¬"""
    formatted_text = ""
    for turn in conversation:
        if turn['role'] == 'user':
            formatted_text += f"User: {turn['content']}\n"
        elif turn['role'] == 'assistant':
            formatted_text += f"Assistant: {turn['content']}\n"
    return formatted_text.strip()


def process_chatbot_arena_dataset(dataset, tokenizer, max_length: int = 1024) -> Dataset:
    """å¤„ç†Chatbot Arenaæ•°æ®é›†"""
    
    def process_batch(batch):
        """æ‰¹å¤„ç†èŠå¤©æœºå™¨äººç«æŠ€åœºæ•°æ®"""
        processed_texts = []
        processed_lengths = []
        
        for i in range(len(batch['winner'])):
            # é€‰æ‹©è·èƒœçš„å¯¹è¯
            if batch['winner'][i] == 'model_a':
                conversation = batch['conversation_a'][i]
            elif batch['winner'][i] == 'model_b':
                conversation = batch['conversation_b'][i]
            else:  # tieçš„æƒ…å†µï¼Œéšæœºé€‰æ‹©ä¸€ä¸ª
                conversation = random.choice([batch['conversation_a'][i], batch['conversation_b'][i]])
            
            # åªå¤„ç†è‹±æ–‡å¯¹è¯
            if batch['language'][i] == 'English' and conversation:
                formatted_text = format_conversation(conversation)
                
                # æ£€æŸ¥é•¿åº¦æ˜¯å¦åˆé€‚
                tokens = tokenizer.encode(formatted_text)
                if len(tokens) <= max_length and len(tokens) > 20:
                    processed_texts.append(formatted_text)
                    processed_lengths.append(len(tokens))
        
        return {
            'text': processed_texts,
            'length': processed_lengths
        }
    
    # ä½¿ç”¨mapæ‰¹å¤„ç†
    print("å¤„ç†æ•°æ®é›†...")
    processed_dataset = dataset.map(
        process_batch,
        batched=True,
        batch_size=1000,  # æ¯æ‰¹å¤„ç†1000ä¸ªæ ·æœ¬
        remove_columns=dataset.column_names,  # åˆ é™¤åŸå§‹åˆ—
        desc="Processing Chatbot Arena dataset",  # æ˜¾ç¤ºè¿›åº¦æ¡
        num_proc=num_proc,  # ä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿ
    )
    
    # è¿‡æ»¤æ‰ç©ºçš„æ‰¹æ¬¡
    processed_dataset = processed_dataset.filter(
        lambda x: len(x['text']) > 0,
        desc="Filtering empty batches"
    )
    
    print(f"å¤„ç†å®Œæˆï¼Œå…±æœ‰ {len(processed_dataset)} æ¡æœ‰æ•ˆå¯¹è¯")
    return processed_dataset

# å¦‚æœä½¿ç”¨transformersçš„Trainerï¼Œåˆ™éœ€è¦æ‰‹åŠ¨å¤„ç†æ–‡æœ¬å’Œæ ‡ç­¾ï¼Œæˆ‘è¿™é‡Œæ˜¯æ²¡æœ‰ç”¨çš„
# def tokenize_function(self, examples):
#     """åˆ†è¯å‡½æ•°"""
#     # åœ¨æ–‡æœ¬æœ«å°¾æ·»åŠ EOS token </s>
#     texts = [text + self.tokenizer.eos_token for text in examples["text"]]
    
#     #è¿™é‡Œçš„tokenizedæ˜¯ä¸€ä¸ªbatchçš„ç»“æœ
#     tokenized = self.tokenizer(
#         texts,
#         truncation=True,
#         padding=False,
#         max_length=self.max_seq_length,
#         return_overflowing_tokens=False,    # è¶…è¿‡maxseq_lengthçš„æ–‡æœ¬å°†è¢«ä¸¢å¼ƒ
#     )
    
#     # å¯¹äºå› æœè¯­è¨€æ¨¡å‹ï¼Œlabelsåº”è¯¥æ˜¯input_idså‘å³ç§»åŠ¨ä¸€ä½
#     # input_ids: [token1, token2, token3, ..., tokenN]
#     # labels:    [token2, token3, ..., tokenN, EOS]
#     labels = []
#     for input_ids in tokenized["input_ids"]:
#         # åˆ›å»ºå‘å³ç§»åŠ¨ä¸€ä½çš„labels
#         label = input_ids[1:] + [self.tokenizer.eos_token_id]
#         labels.append(label)
    
#     tokenized["labels"] = labels
    
#     return tokenized

class QLoRATrainerTRL:
    """åŸºäºTRL SFTTrainerçš„QLoRAå¾®è°ƒè®­ç»ƒå™¨"""
    
    def __init__(
        self,
        model_name: str,
        tokenizer_path: str = "../tokenizer/byte_level_bpe_tokenizer_v1.json",
        output_dir: str = "./sft_output",
        max_seq_length: int = 1024,
    ):
        self.model_name = model_name
        self.tokenizer_path = tokenizer_path
        self.output_dir = output_dir
        self.max_seq_length = max_seq_length
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        self.setup_model_and_tokenizer()
    
    def setup_model_and_tokenizer(self):
        """è®¾ç½®æ¨¡å‹å’Œåˆ†è¯å™¨"""
        print(f"åŠ è½½æ¨¡å‹: {self.model_name}")
        
        local_rank = int(os.environ.get("LOCAL_RANK", 0))

        # é…ç½®4bité‡åŒ–
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_use_double_quant=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.float16,  # æ”¹ä¸ºfloat16é¿å…æ•°æ®ç±»å‹ä¸åŒ¹é…
        )

        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            quantization_config=bnb_config,
            # device_map={'': torch.cuda.current_device()},  # 4bité‡åŒ–å¿…é¡»æŒ‡å®šå•ä¸€è®¾å¤‡
            device_map={"": local_rank},   # <---- å…³é”®
            trust_remote_code=True,
            torch_dtype=torch.float16,  # æ˜ç¡®æ•°æ®ç±»å‹
        )
        
        # åŠ è½½åˆ†è¯å™¨ - ä½¿ç”¨è‡ªå®šä¹‰çš„å­—èŠ‚çº§BPEåˆ†è¯å™¨ï¼Œç¡®ä¿è®¾ç½®äº†æ‰€æœ‰å¿…è¦çš„ç‰¹æ®Štoken
        self.tokenizer = PreTrainedTokenizerFast(
            tokenizer_file=self.tokenizer_path,
            bos_token="<s>", 
            pad_token="<pad>", 
            eos_token="</s>", 
            unk_token="<unk>",
        )
        
        # ç¡®ä¿æ¨¡å‹configä¸åˆ†è¯å™¨tokenè®¾ç½®ä¸€è‡´
        if self.model.config.pad_token_id is None:
            self.model.config.pad_token_id = self.tokenizer.pad_token_id
        
        # éªŒè¯ç‰¹æ®Štoken
        print(f"åˆ†è¯å™¨é…ç½®: pad_token_id={self.tokenizer.pad_token_id}, vocab_size={self.tokenizer.vocab_size}")
        if self.tokenizer.pad_token_id >= self.tokenizer.vocab_size:
            raise ValueError(f"Pad token IDè¶…å‡ºè¯æ±‡è¡¨èŒƒå›´: {self.tokenizer.pad_token_id} >= {self.tokenizer.vocab_size}")

        '''
        prepare_model_for_kbit_trainingï¼š
        1ã€å†»ç»“æ¨¡å‹å‚æ•°ï¼Œé˜²æ­¢è¯¯æ›´æ–°ã€‚
        2ã€å¤„ç†é‡åŒ–æ¨¡å‹çš„æ¢¯åº¦è®¡ç®—ã€è¾“å…¥è¾“å‡ºç­‰å…¼å®¹æ€§é—®é¢˜ã€‚
        3ã€ç¡®ä¿é‡åŒ–æƒé‡å’Œ LoRA adapter èƒ½æ­£ç¡®ååŒè®­ç»ƒã€‚
        '''
        self.model = prepare_model_for_kbit_training(self.model)
        
        # é…ç½®LoRA - é’ˆå¯¹0.1Bå°æ¨¡å‹ä¼˜åŒ–
        lora_config = LoraConfig(
            r=8,  # å°æ¨¡å‹ä½¿ç”¨è¾ƒå°çš„rankï¼Œé¿å…è¿‡å‚æ•°åŒ–
            lora_alpha=16,  # ç›¸åº”å‡å°alpha scaling
            target_modules=[
                "c_attn", "c_proj"  # GPT-2æ³¨æ„åŠ›å±‚
            ],
            lora_dropout=0.05,  # å°æ¨¡å‹é™ä½dropoutï¼Œä¿æŒå­¦ä¹ èƒ½åŠ›
            bias="none",
            task_type=TaskType.CAUSAL_LM,
        )
        
        # get_peft_modelï¼šæŠŠ LoRA adapter å±‚â€œæ’å…¥â€åˆ°åŸå§‹å¤§æ¨¡å‹ä¸­
        self.model = get_peft_model(self.model, lora_config)
        self.model.print_trainable_parameters()
    
    def formatting_func(self, example):
        """
        TRL SFTTrainerçš„æ ¼å¼åŒ–å‡½æ•°ï¼ˆå½“å‰æœªä½¿ç”¨ï¼‰
        å¦‚æœéœ€è¦å¤æ‚çš„æ•°æ®é¢„å¤„ç†ï¼Œå¯ä»¥ä½¿ç”¨æ­¤å‡½æ•°æ›¿ä»£dataset_text_field
        
        ä½¿ç”¨æ–¹æ³•ï¼š
        - å¦‚æœæ•°æ®éœ€è¦å¤æ‚æ ¼å¼åŒ–ï¼šä½¿ç”¨formatting_funcå‚æ•°
        - å¦‚æœæ•°æ®å­—æ®µç®€å•ç›´æ¥ï¼šä½¿ç”¨dataset_text_fieldå‚æ•°ï¼ˆå½“å‰ä½¿ç”¨ï¼‰
        """
        return example["text"]

    
    def train(
        self,
        train_dataset: Dataset,
        eval_dataset: Optional[Dataset] = None,
        num_train_epochs: int = 3,
        learning_rate: float = 2e-4,
        per_device_train_batch_size: int = 4,
        gradient_accumulation_steps: int = 4,
        warmup_steps: int = 100,
        logging_steps: int = 10,
        save_steps: int = 500,
        eval_steps: int = 500,
        use_wandb: bool = True,
        packing: bool = False,
    ):
        """å¼€å§‹è®­ç»ƒ"""
        
        if use_wandb:
            wandb.init(
                project="qlora-chatbot-finetune-trl",
                name=f"qlora-trl-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
                config={
                    "model_name": self.model_name,
                    "num_train_epochs": num_train_epochs,
                    "learning_rate": learning_rate,
                    "batch_size": per_device_train_batch_size,
                    "gradient_accumulation_steps": gradient_accumulation_steps,
                    "max_seq_length": self.max_seq_length,
                    "packing": packing,
                }
            )
            
        sft_config = SFTConfig(
            output_dir=self.output_dir,
            num_train_epochs=num_train_epochs,
            per_device_train_batch_size=per_device_train_batch_size,
            per_device_eval_batch_size=per_device_train_batch_size,
            gradient_accumulation_steps=gradient_accumulation_steps,
            warmup_steps=warmup_steps,
            learning_rate=learning_rate,
            logging_steps=logging_steps,
            save_steps=save_steps,
            eval_steps=eval_steps if eval_dataset is not None else None,
            eval_strategy=("steps" if eval_dataset is not None else "no"),
            save_strategy=("steps" if eval_dataset is not None else "no"),
            load_best_model_at_end=True if eval_dataset is not None else False,
            metric_for_best_model="eval_loss" if eval_dataset is not None else None,
            greater_is_better=False,
            report_to="wandb" if use_wandb else "none",
            run_name=f"qlora-trl-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
            dataloader_pin_memory=False,
            remove_unused_columns=False,
            max_length=self.max_seq_length,
            dataset_text_field="text",
            packing=packing,
            fp16=False,  # å¯ç”¨fp16ä¸é‡åŒ–é…ç½®åŒ¹é…
            bf16=False,  # ç¦ç”¨bf16
        )
            

        trainer = SFTTrainer(
            model=self.model,
            args=sft_config,
            train_dataset=train_dataset,
            eval_dataset=eval_dataset,
            processing_class=self.tokenizer,
        )
        
        # å¼€å§‹è®­ç»ƒ
        print("å¼€å§‹TRL SFTè®­ç»ƒ...")
        trainer.train()
        
        # åœ¨æ¨¡å‹è¢«get_peft_modelåŒ…è£…åï¼Œtrainer.save_model()åªä¿å­˜LoRAé€‚é…å™¨
        # å› ä¸ºæˆ‘åè¾¹è¿˜è¦ç”¨è¿™ä¸ªæ¨¡å‹æ¥è®­ç»ƒå¥–åŠ±æ¨¡å‹å¹¶ä¸”ä½œä¸ºå¼ºåŒ–å­¦ä¹ å¾®è°ƒçš„ç­–ç•¥æ¨¡å‹ï¼Œæ‰€ä»¥æˆ‘é€‰æ‹©äº†åˆå¹¶LORAæƒé‡,ç›´æ¥åŠ è½½æ›´æ–¹ä¾¿
        print("ä¿å­˜LoRAé€‚é…å™¨...")
        trainer.save_model()
        
        # ä¿å­˜åˆå¹¶åçš„å®Œæ•´æ¨¡å‹ï¼ˆæ¨èç”¨äºåç»­ä½¿ç”¨ï¼‰
        print("åˆå¹¶å¹¶ä¿å­˜å®Œæ•´æ¨¡å‹...")
        merged_model_dir = f"{self.output_dir}_merged"
        os.makedirs(merged_model_dir, exist_ok=True)
        
        # åˆå¹¶LoRAæƒé‡åˆ°åŸºç¡€æ¨¡å‹
        merged_model = self.model.merge_and_unload()
        merged_model.save_pretrained(merged_model_dir)
        # self.tokenizer.save_pretrained(merged_model_dir)
        
        print(f"å®Œæ•´æ¨¡å‹å·²ä¿å­˜åˆ°: {merged_model_dir}")
        
        if use_wandb:
            wandb.finish()
        
        return trainer

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹åŸºäºTRLçš„QLoRAå¾®è°ƒ...")

    # 1. åŠ è½½åˆ†è¯å™¨
    tokenizer_path = "../tokenizer/byte_level_bpe_tokenizer_v1.json"
    print(f"åŠ è½½åˆ†è¯å™¨: {tokenizer_path}")
    tokenizer = PreTrainedTokenizerFast(
        tokenizer_file=tokenizer_path,
        bos_token="<s>", 
        pad_token="<pad>", 
        eos_token="</s>",
        unk_token="<unk>"
    )
    
    # 2. åŠ è½½å¹¶å¤„ç†æ•°æ®é›†
    print("åŠ è½½Chatbot Arenaæ•°æ®é›†...")
    ds = load_dataset("lmsys/chatbot_arena_conversations")
    dataset = ds['train']
    processed_dataset = process_chatbot_arena_dataset(dataset, tokenizer, max_length=1024)
    
    # 3. åˆ†å‰²æ•°æ®é›†
    dataset_split = processed_dataset.train_test_split(test_size=0.1, seed=42)
    train_dataset = dataset_split['train']
    eval_dataset = dataset_split['test']
    
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"éªŒè¯é›†å¤§å°: {len(eval_dataset)}")
    
    # # 4. æ£€æŸ¥ä¸€äº›æ ·æœ¬ï¼ˆå¯é€‰ï¼‰
    # print("\næ ·æœ¬æ•°æ®é¢„è§ˆ:")
    # for i in range(min(2, len(train_dataset))):
    #     print(f"æ ·æœ¬ {i+1}:")
    #     print(train_dataset[i]['text'][:200] + "...")
    #     print("-" * 50)
    
    # 5. åˆå§‹åŒ–TRLè®­ç»ƒå™¨
    model_name = "../output"  # ä½¿ç”¨æœ¬åœ°é¢„è®­ç»ƒå®Œæˆçš„æ¨¡å‹
    
    trainer = QLoRATrainerTRL(
        model_name=model_name,
        tokenizer_path=tokenizer_path,
        output_dir="./sft_output",
        max_seq_length=1024,
    )
    
    # 6. å¼€å§‹è®­ç»ƒ
    trainer.train(
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        num_train_epochs=2,  # ğŸ”§ å‡å°‘è®­ç»ƒè½®æ•°ï¼Œé¿å…è¿‡æ‹Ÿåˆ
        learning_rate=1e-4,  # ğŸ”§ é™ä½å­¦ä¹ ç‡ï¼Œæ›´æ¸©å’Œçš„å¾®è°ƒ
        per_device_train_batch_size=1,  # é¿å…paddingé—®é¢˜ï¼Œä½†é€šè¿‡å¤šGPUå¹¶è¡Œæé«˜åå
        gradient_accumulation_steps=16,  # ä¿æŒæœ‰æ•ˆbatch size
        warmup_steps=100,  # ğŸ”§ å‡å°‘warmupæ­¥æ•°
        logging_steps=10,
        save_steps=200,
        eval_steps=200,
        use_wandb=False,  # è®¾ç½®ä¸ºTrueå¦‚æœè¦ä½¿ç”¨wandb
        packing=False,  # ç¦ç”¨packingï¼Œé¿å…åºåˆ—é•¿åº¦é—®é¢˜
    )
    
    print("SFTè®­ç»ƒå®Œæˆï¼")
    print(f"LoRAé€‚é…å™¨å·²ä¿å­˜åˆ°: {trainer.output_dir}")
    print(f"å®Œæ•´æ¨¡å‹å·²ä¿å­˜åˆ°: {trainer.output_dir}_merged")
    

if __name__ == "__main__":
    main()
